{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculates coverages for all forecasts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code scales and forecasts for each day with data available. Then for each value of `t_0` and a forecast window of 1 year we calculate the `1-\\alpha=0.1,...,0.99` confidence intervals. For each week in the 1 year forecast we report whether the `1-\\alpha` confidence intervals captured the Fourier smoothed trap data point."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing necessary libraries and turning off warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, importlib, glob, json\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import nbinom as nbinom\n",
    "import itertools\n",
    "sys.path.append( os.path.abspath(os.path.join('..')) )\n",
    "import utils.forecast as forecast\n",
    "import utils.utils as gen_utils\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Opening config file\n",
    "f = open('../fpaths_config.json')\n",
    "paths = json.load(f)\n",
    "\n",
    "raw_data_path = paths['raw_data']\n",
    "smoothed_data_path = paths['smoothed_data']\n",
    "coverages_path = paths[\"coverages_path\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test combinations of scaler and forecast windows"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a prediction on day $t_0$, the scaling window contains the $[t_0-\\text{scaling win}:t_0]$ days of trap data and nn predictions. The scaling window is used for several purposes:\n",
    "* We estimate the probability of success in the negative binomial distribution (p) using the scaling window of trap data:\n",
    "$$\n",
    "p_{avg} = \\frac{1}{n}\\sum_{i=1}^n\\frac{\\mu_i}{\\sigma_i^2}\n",
    "$$\n",
    "where $\\mu_i, \\sigma_i$ are the observed trap mean and standard deviation for week $i$ and $n=\\lfloor \\text{scaling win}/7 \\rfloor$ is the number of weeks in the scaling window (since we have weekly, not daily, trap data)\n",
    "* The scaling factor for the neural network predictions is calculated such that the average neural network predictions in the scaling window is equivalent to the average trap data in the same scaling window\n",
    "$$\n",
    "scaling_{rto} = \\frac{\\overline{\\text{trap}}}{\\overline{\\text{nn}}}\n",
    "$$\n",
    "where $\\overline{\\text{trap}}$ is the average trap data in the scaling window and $\\overline{\\text{nn}}$ is the average neural network prediction in the scaling window.\n",
    "* We use a scaling window of $90$ days."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then for prediction day $t_0$ the forecast window contains the $[t_0:t_0+\\text{forecast win}]$ days of trap data and nn predictions.\n",
    "* The subset of neural network predictions $[t_0-\\text{scaler win}:t_0+\\text{forecast win}]$ is scaled by multiplying the $scaling_{rto}$ defined above\n",
    "* Use the forecast window neural network predictions to estimate the variance $\\sigma^2$ and number of successes $n$ in the negative binomial distribution.\n",
    "$$\n",
    "\\sigma^2 = \\frac{\\hat{nn}}{p_{avg}};\\quad\\quad n = \\frac{\\hat{nn}^2}{\\sigma^2-\\hat{nn}}\n",
    "$$\n",
    "where $\\hat{nn}$ are the neural network predictions (here representing the daily mean of the forecast window) and $p_{avg}$ is defined above.\n",
    "* Convert the neural network predictions into a probablistic forecast using `nbinom.interval`\n",
    "* For each week of trap data in the forecasting window, report wether the confidence interval captures the trap data point.\n",
    "* We use a forecasting window of length $365$ days"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we generate a csv file with columns Site, Scaler_win, Forecast_win, CIs that shows the coverage of each combination of site, scaling window, and forecast window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arboleda site False\n",
      "Playa site False\n",
      "La_Margarita site False\n",
      "Villodas site False\n",
      "Arboleda site True\n",
      "Playa site True\n",
      "La_Margarita site True\n",
      "Villodas site True\n",
      "Arboleda airport False\n",
      "Playa airport False\n",
      "La_Margarita airport False\n",
      "Villodas airport False\n",
      "Arboleda airport True\n",
      "Playa airport True\n",
      "La_Margarita airport True\n",
      "Villodas airport True\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(forecast)\n",
    "\n",
    "if not os.path.exists(coverages_path):\n",
    "    os.mkdir(coverages_path)\n",
    "\n",
    "# Test airport weather compared to true weather and impact of Fourier smoothing\n",
    "# Neural network predictions are always smoothed\n",
    "\n",
    "weather_flags = ['site', 'airport']\n",
    "smoothing_flags = [False, True]\n",
    "\n",
    "weather_smoothing_flags = list(itertools.product(weather_flags, smoothing_flags))\n",
    "\n",
    "for weather_smoothing_flag in weather_smoothing_flags:\n",
    "    weather_flag, smoothing_flag = weather_smoothing_flag\n",
    "\n",
    "    sites = ['Arboleda', 'Playa', 'La_Margarita', 'Villodas']\n",
    "\n",
    "    scaler_wins = [13]\n",
    "    forecast_wins = [52]\n",
    "\n",
    "    scaler_forecast_wins = list(itertools.product(scaler_wins, forecast_wins))\n",
    "\n",
    "    for site in sites:\n",
    "        if smoothing_flag:\n",
    "            nn_fil_name = '{}/{}_{}_smoothed_weekly_predictions.csv'.format(smoothed_data_path,site,weather_flag)\n",
    "            ofil = '{}/{}_{}_smoothed_coverages.csv'.format(coverages_path, site, weather_flag)\n",
    "        else:\n",
    "            nn_fil_name = '{}/{}_{}_raw_weekly_predictions.csv'.format(raw_data_path,site,weather_flag)\n",
    "            ofil = '{}/{}_{}_raw_coverages.csv'.format(coverages_path, site, weather_flag)\n",
    "\n",
    "        print(site, weather_flag, smoothing_flag)\n",
    "        site_info = [site, weather_flag, smoothing_flag]\n",
    "\n",
    "        site_nn_data = gen_utils.load_csv(nn_fil_name)\n",
    "        site_nn_data.Datetime = pd.to_datetime(site_nn_data.Datetime)\n",
    "        \n",
    "        if not os.path.exists(ofil):\n",
    "            header = 'Site\\tt_0\\talpha\\t'\n",
    "            for i in range(1,53):\n",
    "                header += 'wk{}\\t'.format(i)\n",
    "            header += '\\n'\n",
    "            with open(ofil, 'w') as f:\n",
    "                f.write(header)\n",
    "                f.close() \n",
    "        forecast.coverage_analysis(site_info, site_nn_data, scaler_forecast_wins, ofil)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8838183fa67f399c954c93f3e2ba6176d25d363535a2fcfea60ba719aaa703a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
