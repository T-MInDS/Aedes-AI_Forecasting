{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculates squared error metrics including overall and weekly analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use RMSE and to assess the accuracy of a forecast. Let $t_0$ be the first day of a forecast and $f_{win}$ be the forecast length. Then we define\n",
    "\n",
    "* Root mean square error (RMSE)\n",
    "$$\n",
    "RMSE = \\sqrt{\\frac{\\sum_{i=t_0}^{t_0+f_{win}} (\\text{trap}_i - \\hat{y}_i)^2}{f_{win}}}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "where $\\text{trap}_i$ is the trap count and $\\hat{y}_i$ is the smoothed neural network prediction for day $i$. We report average metric values, averging over slightly different scales, as described below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing necessary libraries and turning off warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, importlib, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "from scipy.stats import nbinom as nbinom  \n",
    "import itertools\n",
    "sys.path.append( os.path.abspath(os.path.join('..')) )\n",
    "\n",
    "\n",
    "import utils.forecast as forecast\n",
    "import utils.utils as gen_utils\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Opening config file\n",
    "f = open('../fpaths_config.json')\n",
    "paths = json.load(f)\n",
    "\n",
    "raw_data_path = paths['raw_data']\n",
    "smoothed_data_path = paths['smoothed_data']\n",
    "metric_fil = paths[\"mean_metric_fil\"]\n",
    "amt_metrics_path = paths['amt_metrics']\n",
    "scaling_rto_fil = paths[\"scaling_rto_fil\"]\n",
    "baseline_scaling_rto_fil = paths[\"baseline_scaling_rto_fil\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall mean metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we compute the average RMSE across all forecasts. We test combinations of scaler windows and forecast windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(forecast)\n",
    "\n",
    "with open(metric_fil, 'w') as f:\n",
    "    f.write('Site\\tWeather\\tScaler_win\\tForecast_win\\tTrap_smoothing_flag\\tRMSE_mu\\tRMSE_sig\\n')\n",
    "\n",
    "# Test site and airport weather compared to raw and smoothed trap\n",
    "# Neural network predictions are always smoothed\n",
    "weather_flags = ['site', 'airport']\n",
    "smoothing_flags = [False, True]\n",
    "\n",
    "weather_smoothing_flags = list(itertools.product(weather_flags, smoothing_flags))\n",
    "\n",
    "for weather_smoothing_flag in weather_smoothing_flags:\n",
    "    weather_flag = weather_smoothing_flag[0]\n",
    "    smoothing_flag = weather_smoothing_flag[-1]\n",
    "\n",
    "    sites = ['Arboleda', 'Playa', 'La_Margarita', 'Villodas']\n",
    "\n",
    "    scaler_wins = [4, 8, 13, 17, 21, 26]\n",
    "    forecast_wins = [3, 4, 8, 17, 21, 30, 34, 52, 80, 150]\n",
    "\n",
    "    scaler_forecast_wins = list(itertools.product(scaler_wins, forecast_wins))\n",
    "    today = date.today().strftime('%m%d%y')\n",
    "\n",
    "    for site in sites:\n",
    "        if smoothing_flag:\n",
    "            nn_fil_name = '{}/{}_{}_smoothed_weekly_predictions.csv'.format(smoothed_data_path,site,weather_flag)\n",
    "        else:\n",
    "            nn_fil_name = '{}/{}_{}_raw_weekly_predictions.csv'.format(raw_data_path,site,weather_flag)\n",
    "\n",
    "        print(site, weather_flag, smoothing_flag)\n",
    "        site_info = [site, weather_flag, smoothing_flag]\n",
    "        site_nn_data = gen_utils.load_csv(nn_fil_name)\n",
    "        site_nn_data.Datetime = pd.to_datetime(site_nn_data.Datetime)\n",
    "\n",
    "        forecast.avg_metric_analysis(site_info, site_nn_data, scaler_forecast_wins, metric_fil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define a baseline forecast by scaling the neural network predictions to the mean of the site trap data for either 80 or 150 weeks, depending on location. We then compute the metrics for this baseline forecast and average over the 6 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Metrics for baseline forecast\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "importlib.reload(forecast)\n",
    "\n",
    "weather_flags = ['site', 'airport']\n",
    "smoothing_flags = [False, True]\n",
    "\n",
    "weather_smoothing_flags = list(itertools.product(weather_flags, smoothing_flags))\n",
    "\n",
    "for weather_smoothing_flag in weather_smoothing_flags:\n",
    "    weather_flag = weather_smoothing_flag[0]\n",
    "    smoothing_flag = weather_smoothing_flag[-1]\n",
    "    \n",
    "    sites = ['Arboleda', 'Playa', 'La_Margarita', 'Villodas']\n",
    "\n",
    "    for site in sites:\n",
    "        if smoothing_flag:\n",
    "            nn_fil_name = '{}/{}_{}_smoothed_weekly_predictions.csv'.format(smoothed_data_path,site,weather_flag)\n",
    "        else:\n",
    "            nn_fil_name = '{}/{}_{}_raw_weekly_predictions.csv'.format(raw_data_path,site,weather_flag)\n",
    "\n",
    "        site_nn_data = gen_utils.load_csv(nn_fil_name)\n",
    "        site_nn_data.Datetime = pd.to_datetime(site_nn_data.Datetime)\n",
    "    \n",
    "        site = '{}_baseline'.format(site)\n",
    "    \n",
    "        if 'la_margarita' in site.lower():\n",
    "            #In MoLS the baseline is ~150weeks of trap data for La Margarita\n",
    "            f_wins = [150]\n",
    "        else:\n",
    "            #And ~80weeks of trap data for Villodas, Arboleda, and Playa\n",
    "            f_wins = [80]\n",
    "        \n",
    "        today = date.today().strftime('%m%d%y')\n",
    "\n",
    "        for f_win in f_wins:\n",
    "            rmses = []\n",
    "        \n",
    "            for i in range(0,len(site_nn_data) - f_win):\n",
    "                subset = site_nn_data.copy(deep=True)\n",
    "                subset = subset.iloc[i:i+f_win,:]\n",
    "\n",
    "                scaler = forecast.scale_rto(subset)\n",
    "                scaled_nn_preds = scaler*subset['Neural Network']\n",
    "            \n",
    "                trap = subset.Ref.values\n",
    "                nn = scaled_nn_preds.values\n",
    "            \n",
    "                rmse = mse(trap, nn, squared=False)\n",
    "                \n",
    "                rmses.append(rmse)\n",
    "                \n",
    "        \n",
    "            avg_rmse = np.average(rmses)               \n",
    "            sig_rmse = np.std(rmses)\n",
    "\n",
    "            quant = np.quantile(rmses, .25)\n",
    "            first_quant = np.nanargmin(np.abs(rmses - quant))\n",
    "            print(site, weather_flag, smoothing_flag, first_quant)\n",
    "\n",
    "    \n",
    "            with open(metric_fil, 'a') as f:\n",
    "                f.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format(site, weather_flag, 0, f_win,\n",
    "                                                                        smoothing_flag, avg_rmse, sig_rmse))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amt metric analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to see how the quality of forecasts change over time. We create forecasts using a 13 week scaling window and 52 week forecasting window. Then we compute the average metric for a 4 weeks worth of predictions (i.e. weeks 1-4 after $t_0$, 5-9 weeks after $t_0$, ...). We report these results for all $t_0$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(forecast)\n",
    "\n",
    "# Test airport weather compared to true weather and impact of Fourier smoothing\n",
    "# Neural network predictions are always smoothed\n",
    "weather_flags = ['site', 'airport']\n",
    "smoothing_flags = [False, True]\n",
    "\n",
    "weather_smoothing_flags = list(itertools.product(weather_flags, smoothing_flags))\n",
    "\n",
    "if not os.path.exists(amt_metrics_path):\n",
    "    os.mkdir(amt_metrics_path)\n",
    "\n",
    "#Chunk of time to calculate metrics (i.e. 1 wk,...len(weekly) wks)\n",
    "amt = 4\n",
    "\n",
    "for weather_smoothing_flag in weather_smoothing_flags:\n",
    "    weather_flag = weather_smoothing_flag[0]\n",
    "    smoothing_flag = weather_smoothing_flag[-1]\n",
    "\n",
    "    sites = ['Arboleda', 'Playa', 'La_Margarita', 'Villodas']\n",
    "\n",
    "    scaler_wins = [13]\n",
    "    forecast_wins = [52]\n",
    "\n",
    "    scaler_forecast_wins = list(itertools.product(scaler_wins, forecast_wins))\n",
    "    today = date.today().strftime('%m%d%y')\n",
    "\n",
    "    for site in sites:\n",
    "        if smoothing_flag:\n",
    "            nn_fil_name = '{}/{}_{}_smoothed_weekly_predictions.csv'.format(smoothed_data_path,site,weather_flag)\n",
    "            metric_fil = '{}/{}_{}_smoothed_{}amt_metrics.csv'.format(amt_metrics_path,site,weather_flag,amt)\n",
    "        else:\n",
    "            nn_fil_name = '{}/{}_{}_raw_weekly_predictions.csv'.format(raw_data_path,site,weather_flag)\n",
    "            metric_fil = '{}/{}_{}_raw_{}amt_metrics.csv'.format(amt_metrics_path,site,weather_flag,amt)\n",
    "\n",
    "        print(site, weather_flag, smoothing_flag)\n",
    "        site_info = [site, weather_flag, smoothing_flag]\n",
    "        site_nn_data = gen_utils.load_csv(nn_fil_name)\n",
    "        site_nn_data.Datetime = pd.to_datetime(site_nn_data.Datetime)\n",
    "\n",
    "        if not os.path.exists(metric_fil):\n",
    "            header = 'Site\\tWeather\\tScaler_win\\tForecast_win\\tTrap_smoothing_flag\\tt_0\\tTotal_RMSE\\t'\n",
    "            for i in range(1,forecast_wins[0], amt):\n",
    "                header += 'amt{}_RMSE\\t'.format(i)\n",
    "    \n",
    "            with open(metric_fil, 'w') as f:\n",
    "                f.write('{}\\n'.format(header))\n",
    "                f.close()\n",
    "        site_nn_data = gen_utils.load_csv(nn_fil_name)\n",
    "        site_nn_data.Datetime = pd.to_datetime(site_nn_data.Datetime)\n",
    "\n",
    "        forecast.t0_metric_analysis(site_info, site_nn_data, scaler_forecast_wins, metric_fil, amt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling rto over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(forecast)\n",
    "\n",
    "# Test site and airport weather compared to raw and smoothed trap\n",
    "# Neural network predictions are always smoothed\n",
    "weather_flags = ['site', 'airport']\n",
    "smoothing_flags = [False, True]\n",
    "\n",
    "weather_smoothing_flags = list(itertools.product(weather_flags, smoothing_flags))\n",
    "\n",
    "results = pd.DataFrame(columns=['Site', 'Weather', 'Smoothing', 'Scaler_win', 't_0', 'Scaler_rto'])\n",
    "\n",
    "for weather_smoothing_flag in weather_smoothing_flags:\n",
    "    weather_flag = weather_smoothing_flag[0]\n",
    "    smoothing_flag = weather_smoothing_flag[-1]\n",
    "\n",
    "    sites = ['Arboleda', 'Playa', 'La_Margarita', 'Villodas']\n",
    "\n",
    "    scaler_wins = [13]\n",
    "\n",
    "    for site in sites:\n",
    "        if smoothing_flag:\n",
    "            nn_fil_name = '{}/{}_{}_smoothed_weekly_predictions.csv'.format(smoothed_data_path,site,weather_flag)\n",
    "        else:\n",
    "            nn_fil_name = '{}/{}_{}_raw_weekly_predictions.csv'.format(raw_data_path,site,weather_flag)\n",
    "\n",
    "        print(site, weather_flag, smoothing_flag)\n",
    "        site_info = [site, weather_flag, smoothing_flag]\n",
    "        site_nn_data = gen_utils.load_csv(nn_fil_name)\n",
    "        site_nn_data.Datetime = pd.to_datetime(site_nn_data.Datetime)\n",
    "\n",
    "        scaler_df = forecast.scaler_analysis(site_nn_data, scaler_wins)\n",
    "        scaler_df = scaler_df.assign(Site=site, Weather=weather_flag, Smoothing=smoothing_flag, Scaler_win=90)     \n",
    "        results = pd.concat([results, scaler_df])\n",
    "    \n",
    "results.to_csv(scaling_rto_fil, sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(forecast)\n",
    "\n",
    "# Test site and airport weather compared to raw and smoothed trap\n",
    "# Neural network predictions are always smoothed\n",
    "weather_flags = ['site', 'airport']\n",
    "smoothing_flags = [True]\n",
    "\n",
    "weather_smoothing_flags = list(itertools.product(weather_flags, smoothing_flags))\n",
    "\n",
    "results = pd.DataFrame(columns=['Site', 'Weather', 'Smoothing', 'Scaler_win', 't_0', 'Scaler_rto'])\n",
    "\n",
    "for weather_smoothing_flag in weather_smoothing_flags:\n",
    "    weather_flag = weather_smoothing_flag[0]\n",
    "    smoothing_flag = weather_smoothing_flag[-1]\n",
    "\n",
    "    sites = ['Arboleda', 'Playa', 'La_Margarita', 'Villodas']\n",
    "\n",
    "    for site in sites:\n",
    "        if smoothing_flag:\n",
    "            nn_fil_name = '{}/{}_{}_smoothed_weekly_predictions.csv'.format(smoothed_data_path,site,weather_flag)\n",
    "        else:\n",
    "            nn_fil_name = '{}/{}_{}_raw_weekly_predictions.csv'.format(raw_data_path,site,weather_flag)\n",
    "\n",
    "        if 'la_margarita' in site.lower():\n",
    "            #In MoLS the baseline is ~150weeks of trap data for La Margarita\n",
    "            scaler_wins = [150]\n",
    "        else:\n",
    "            #And ~80weeks of trap data for Villodas, Arboleda, and Playa\n",
    "            scaler_wins = [80]\n",
    "\n",
    "        print(site, weather_flag, smoothing_flag)\n",
    "        site_info = [site, weather_flag, smoothing_flag]\n",
    "        site_nn_data = gen_utils.load_csv(nn_fil_name)\n",
    "        site_nn_data.Datetime = pd.to_datetime(site_nn_data.Datetime)\n",
    "\n",
    "        scaler_df = forecast.scaler_analysis(site_nn_data, scaler_wins)\n",
    "        scaler_df = scaler_df.assign(Site=site, Weather=weather_flag, Smoothing=smoothing_flag, Scaler_win=90)     \n",
    "        results = pd.concat([results, scaler_df])\n",
    "    \n",
    "results.to_csv(baseline_scaling_rto_fil, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(forecast)\n",
    "\n",
    "site = 'Arboleda'\n",
    "scaler_win = 13\n",
    "forecast_win = 52\n",
    "    \n",
    "nn_fil_name = '{}/{}_site_smoothed_weekly_predictions.csv'.format(smoothed_data_path,site)\n",
    "\n",
    "site_nn_data = gen_utils.load_csv(nn_fil_name)\n",
    "site_nn_data = site_nn_data.iloc[0:0+scaler_win+forecast_win,:]\n",
    "site_nn_data.Datetime = pd.to_datetime(site_nn_data.Datetime)\n",
    "\n",
    "l_quant, u_quant, ns, mean_p, scaled_nn_preds = forecast.main_analysis(scaler_win, forecast_win, 0.68, site_nn_data)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(site_nn_data.Datetime, scaled_nn_preds)\n",
    "plt.plot(site_nn_data.Datetime.iloc[-len(l_quant):], l_quant)\n",
    "plt.plot(site_nn_data.Datetime.iloc[-len(l_quant):], u_quant)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8838183fa67f399c954c93f3e2ba6176d25d363535a2fcfea60ba719aaa703a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
