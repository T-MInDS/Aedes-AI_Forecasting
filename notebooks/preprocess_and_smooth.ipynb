{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smooth trap data and store resulting dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code reads in the dataframes with the trap and neural network counts, converts them to a weekly estimate, and smoothes trap data using a 3 week moving average. The resulting dataframes are stored in `data/Smoothed/`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start by importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, importlib, glob, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools, sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append( os.path.abspath(os.path.join('..')) )\n",
    "import utils.utils as gen_utils\n",
    "import utils.forecast as forecast\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Opening config file\n",
    "f = open('../fpaths_config.json')\n",
    "paths = json.load(f)\n",
    "\n",
    "raw_data_path = paths['raw_data']\n",
    "smoothed_data_path = paths['smoothed_data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save weekly raw and simple smoothing using 3wk moving average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reads in csv files named `[site]_daily_predictions.csv` with columns `[Location, Datetime, Ref, Ref_sd, Neural Network]` and converts daily predictions to weekly predictions. Saves files with raw AGO and with smoothed AGO in `../data/Raw` and `../data/Smoothed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Raw AGO\n",
    "sites = ['Arboleda', 'Playa', 'La_Margarita', 'Villodas']\n",
    "weathers = ['site', 'airport']\n",
    "site_weathers = list(itertools.product(sites, weathers))\n",
    "\n",
    "for site_weather in site_weathers:\n",
    "    site, weather = site_weather\n",
    "\n",
    "    if weather=='airport':\n",
    "        nn_fil_name = '../data/{}_airport_daily_predictions.csv'.format(site)    \n",
    "    else:\n",
    "        nn_fil_name = '../data/{}_site_daily_predictions.csv'.format(site)\n",
    "\n",
    "    site_nn_data = gen_utils.load_csv(nn_fil_name)\n",
    "    site_nn_data.Datetime = pd.to_datetime(site_nn_data.Datetime)\n",
    "    \n",
    "    weekly = site_nn_data.groupby(pd.Grouper(key='Datetime', freq='W-SAT')).agg({'Ref': np.mean,\n",
    "                                                                                 'Ref_sd': np.mean,\n",
    "                                                                                 'Neural Network': np.sum})             \n",
    "    weekly.loc[weekly.index[0], 'Neural Network'] = 3.5*weekly.loc[weekly.index[0], 'Neural Network']\n",
    "    weekly.loc[weekly.index[-1], 'Neural Network'] = 8/7*weekly.loc[weekly.index[-1], 'Neural Network']\n",
    "    \n",
    "    smoothed_nn = forecast.moving_avg(weekly['Neural Network'], n=3)\n",
    "    weekly['Neural Network'] = smoothed_nn \n",
    "\n",
    "    weekly = weekly.assign(Location=site)\n",
    "    weekly = weekly[['Location', 'Ref', 'Ref_sd', 'Neural Network']]\n",
    "    weekly.to_csv('{}/{}_{}_raw_weekly_predictions.csv'.format(raw_data_path,site,weather))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smoothed AGO\n",
    "sites = ['Arboleda', 'Playa', 'La_Margarita', 'Villodas']\n",
    "weathers = ['site', 'airport']\n",
    "site_weathers = list(itertools.product(sites, weathers))\n",
    "\n",
    "for site_weather in site_weathers:\n",
    "    site, weather = site_weather\n",
    "\n",
    "    if weather=='airport':\n",
    "        nn_fil_name = '../data/{}_airport_daily_predictions.csv'.format(site)    \n",
    "    else:\n",
    "        nn_fil_name = '../data/{}_site_daily_predictions.csv'.format(site)\n",
    "\n",
    "    site_nn_data = gen_utils.load_csv(nn_fil_name)\n",
    "    site_nn_data.Datetime = pd.to_datetime(site_nn_data.Datetime)\n",
    "                \n",
    "    weekly = site_nn_data.groupby(pd.Grouper(key='Datetime', freq='W-SAT')).agg({'Ref': np.mean,\n",
    "                                                                                 'Ref_sd': np.mean,\n",
    "                                                                                 'Neural Network': np.sum})             \n",
    "    #First week only has 2 days and last week only has 6 days\n",
    "    weekly.loc[weekly.index[0], 'Neural Network'] = 3.5*weekly.loc[weekly.index[0], 'Neural Network']\n",
    "    weekly.loc[weekly.index[-1], 'Neural Network'] = 8/7*weekly.loc[weekly.index[-1], 'Neural Network']\n",
    "        \n",
    "    smoothed_nn = forecast.moving_avg(weekly['Neural Network'], n=3)\n",
    "    weekly['Neural Network'] = smoothed_nn \n",
    "\n",
    "    weekly.Ref = forecast.moving_avg(weekly.Ref, n=3)\n",
    "    weekly.Ref_sd = forecast.moving_avg(weekly.Ref_sd, n=3)\n",
    "    \n",
    "    weekly = weekly.assign(Location=site)\n",
    "    weekly = weekly[['Location', 'Ref', 'Ref_sd', 'Neural Network']]\n",
    "    weekly.to_csv('{}/{}_{}_smoothed_weekly_predictions.csv'.format(smoothed_data_path,site,weather))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8838183fa67f399c954c93f3e2ba6176d25d363535a2fcfea60ba719aaa703a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
